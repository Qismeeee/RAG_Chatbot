# === IMPORT C√ÅC TH∆Ø VI·ªÜN C·∫¶N THI·∫æT ===
import os
import streamlit as st
from audio_recorder_streamlit import audio_recorder
from dotenv import load_dotenv
import PyPDF2
import numpy as np
# Import the search function
from search_embeddings import search_milvus
from langchain_openai import OpenAIEmbeddings

from chat_interface import generate_answer, generate_answer_stream, speech_to_text
import asyncio 
# === THI·∫æT L·∫¨P GIAO DI·ªÜN TRANG WEB ===

def setup_page():
    st.set_page_config(
        page_title="AI Assistant",
        page_icon="üí¨",
        layout="wide"
    )

# === KH·ªûI T·∫†O ·ª®NG D·ª§NG ===


def initialize_app():
    load_dotenv()
    setup_page()

# === THANH C√îNG C·ª§ B√äN TR√ÅI ===


def setup_sidebar():
    with st.sidebar:
        st.title("‚öôÔ∏è C·∫•u h√¨nh")

        st.header("üìö Ngu·ªìn d·ªØ li·ªáu")
        data_source = st.radio("Ch·ªçn ngu·ªìn d·ªØ li·ªáu:", [
                               "C√¢u h·ªèi", "T·∫£i l√™n PDF"])

        return data_source

# === X·ª¨ L√ù T·∫¢I L√äN PDF ===


def handle_pdf_upload():
    uploaded_file = st.file_uploader("Ch·ªçn file PDF", type="pdf")
    if uploaded_file is not None:
        with st.spinner("ƒêang x·ª≠ l√Ω file PDF..."):
            try:
                pdf_reader = PyPDF2.PdfReader(uploaded_file)
                text = ""
                for page in pdf_reader.pages:
                    text += page.extract_text()
                st.success("ƒê√£ t·∫£i v√† x·ª≠ l√Ω file PDF th√†nh c√¥ng!")
                return text
            except Exception as e:
                st.error(f"L·ªói khi x·ª≠ l√Ω file PDF: {str(e)}")
    return None

# === GIAO DI·ªÜN CHAT CH√çNH ===


def setup_chat_interface():
    st.title("üí¨ AI Assistant")
    st.caption("üöÄ Tr·ª£ l√Ω AI ƒë∆∞·ª£c h·ªó tr·ª£ b·ªüi LangChain v√† OpenAI GPT-4")

    if "messages" not in st.session_state:
        st.session_state.messages = [
            {"role": "assistant", "content": "T√¥i c√≥ th·ªÉ gi√∫p g√¨ cho b·∫°n?"}]



def handle_user_input(data_source):
    if data_source == "C√¢u h·ªèi":
        for msg in st.session_state.messages:
            role = "assistant" if msg["role"] == "assistant" else "human"
            st.chat_message(role).write(msg["content"])
        # Create footer container for the microphone
        # footer_container = st.container()
        # with footer_container:
        col1, col2 = st.columns([3, 1])
        with col1:
            prompt = st.chat_input("H√£y h·ªèi t√¥i b·∫•t c·ª© ƒëi·ªÅu g√¨!")
        with col2:
            audio_bytes = audio_recorder(text="", icon_size="2x")
            print("AUDIO: ", audio_bytes)
        
        if audio_bytes:
        # Write the audio bytes to a file
            with st.spinner("Transcribing..."):
                webm_file_path = "temp_audio.mp3"
                with open(webm_file_path, "wb") as f:
                    f.write(audio_bytes)

                transcript = speech_to_text(webm_file_path)
                if transcript:
                    st.session_state.messages.append({"role": "user", "content": transcript})
                    with st.chat_message("user"):
                        st.write(transcript)
                    os.remove(webm_file_path)
        if prompt:
            st.session_state.messages.append(
                {"role": "human", "content": prompt})
            st.chat_message("human").write(prompt)

            # Search using the text directly
            results = search_milvus(prompt)
            print("PROMT: ", prompt)
            # print("RESULTS: ", results)

            # Format results
            formatted_results = []
            for doc in results:
                formatted_results.append({
                    "content": doc.page_content,
                    "source": doc.metadata.get("source", "Unknown"),
                    "chunk_number": doc.metadata.get("chunk_number", "Unknown")
                })

            # Display results
            response = "K·∫øt qu·∫£ t√¨m ki·∫øm:\n\n"
            for idx, result in enumerate(formatted_results, 1):
                response += f"{idx}. Ngu·ªìn: {result['source']}\n"
                response += f"   ƒêo·∫°n s·ªë: {result['chunk_number']}\n"
                response += f"   N·ªôi dung: {result['content'][:200]}...\n\n"

            st.session_state.messages.append(
                    {"role": "assistant", "content": response})
            st.chat_message("assistant").write(response)
            ai_response = generate_answer(prompt, result)
            # print("AI response: ", ai_response)
            st.session_state.messages.append(
                    {"role": "assistant", "content": ai_response})
            # st.chat_message("assistant").write(ai_response)
            st.chat_message("assistant").write_stream(ai_response) #stream response
            
    elif data_source == "T·∫£i l√™n PDF":
        pdf_text = handle_pdf_upload()
        if pdf_text:
            st.session_state.messages.append(
                {"role": "human", "content": pdf_text})
            st.chat_message("human").write(pdf_text)

            # Search using the PDF text directly
            results = search_milvus(pdf_text)

            # Display results
            response = f"Top results: {results}"
            st.session_state.messages.append(
                {"role": "assistant", "content": response})
            st.chat_message("assistant").write(response)
# === H√ÄM CH√çNH ===


def main():
    initialize_app()
    data_source = setup_sidebar()
    setup_chat_interface()
    handle_user_input(data_source)


# Ch·∫°y ·ª©ng d·ª•ng
if __name__ == "__main__":
    main()

# streamlit run streamlit_app.py