import traceback
from langchain_text_splitters import RecursiveCharacterTextSplitter
from chat_interface import generate_answer, speech_to_text
from preprocessing.chunking import generate_doc_id
import streamlit as st
from dotenv import load_dotenv
from langchain_community.callbacks.streamlit import StreamlitCallbackHandler
from langchain_community.chat_message_histories import StreamlitChatMessageHistory
from crawl import crawl_multiple_urls
from langchain_community.document_loaders import RecursiveUrlLoader
from database import search_milvus, seed_milvus
from process_data import handle_upload_file
import PyPDF2
import os
from audio_recorder_streamlit import audio_recorder
import re

from bs4 import BeautifulSoup


def bs4_extractor(html: str) -> str:
    soup = BeautifulSoup(html, "lxml")
    return re.sub(r"\n\n+", "\n\n", soup.text).strip()


def setup_page():
    st.set_page_config(
        page_title="CTU Chatbot Assistant",
        page_icon="ğŸ“",
        layout="wide"
    )


def initialize_app():
    load_dotenv()
    setup_page()


def setup_header():
    st.image("D:/HK1_2024-2025/Chatbot/Chat/images/logoCTU.png", width=300)
    st.markdown(
        """
        <div style="text-align: center; margin-top: -10px; font-size: 18px; color: black; background-color: #FFFF00; padding: 10px; border-radius: 10px;">
            <b>Äá»“ng thuáº­n â€“ Táº­n tÃ¢m â€“ Chuáº©n má»±c â€“ SÃ¡ng táº¡o</b>
        </div>
        """,
        unsafe_allow_html=True
    )


def setup_sidebar():
    with st.sidebar:
        setup_header()
        st.title("âš™ï¸ Cáº¥u hÃ¬nh CTU Chatbot Assistant")

        st.header("ğŸ¤– Model AI")
        model_choice = st.radio(
            "Chá»n AI Model Ä‘á»ƒ tráº£ lá»i:",
            ["OpenAI GPT-4o", "Ollama (Local)"]
        )
        st.header("ğŸ”¤ Embeddings Model")
        embeddings_choice = st.radio(
            "Chá»n Embeddings Model:",
            ["OpenAI", "Ollama"]
        )
        # use_ollama_embeddings = (embeddings_choice == "Ollama")
        use_ollama_embeddings = False

        st.header("ğŸ“š Nguá»“n dá»¯ liá»‡u")
        data_source = st.radio(
            "Chá»n nguá»“n dá»¯ liá»‡u:",
            ["File Local", "URL trá»±c tiáº¿p"]
        )

        if data_source == "File Local":
            handle_local_file(use_ollama_embeddings)
        else:
            handle_url_input(use_ollama_embeddings)

        st.header("ğŸ” Collection Ä‘á»ƒ truy váº¥n")
        collection_to_query = st.text_input(
            "Nháº­p tÃªn collection cáº§n truy váº¥n:",
            "data_ctu",
            help="Nháº­p tÃªn collection báº¡n muá»‘n sá»­ dá»¥ng Ä‘á»ƒ tÃ¬m kiáº¿m thÃ´ng tin"
        )

        return model_choice, collection_to_query


def handle_local_file(use_ollama_embeddings: bool):
    collection_name = st.text_input(
        "TÃªn collection trong Milvus:",
        "data_ctu",
        help="Nháº­p tÃªn collection báº¡n muá»‘n lÆ°u trong Milvus"
    )
    files = st.file_uploader("Táº£i lÃªn PDF", type="pdf",
                             accept_multiple_files=True)
    print("Uploaded_file: ", files)
    for uploaded_file in files:
        with st.spinner("Äang xá»­ lÃ½ file PDF..."):
            try:
                handle_upload_file(
                    uploaded_file, collection_name, use_ollama_embeddings)
                st.toast(
                    f"ÄÃ£ táº£i vÃ  xá»­ lÃ½ file {uploaded_file.name} thÃ nh cÃ´ng!", icon="âœ…")
            except Exception as e:
                print(f"Lá»—i khi xá»­ lÃ½ file PDF: {str(e)}")
                print("Error: ", traceback.format_exc())
                st.toast(f"Lá»—i khi xá»­ lÃ½ file PDF: {str(e)}")
    files = []


def handle_url_input(use_ollama_embeddings: bool):
    collection_name = st.text_input(
        "TÃªn collection trong Milvus:",
        "data_ctu",
        help="Nháº­p tÃªn collection báº¡n muá»‘n lÆ°u trong Milvus"
    )
    url = st.text_input("Nháº­p URL:", "https://www.ctu.edu.vn")

    if st.button("Crawl dá»¯ liá»‡u"):
        if not collection_name:
            st.error("Vui lÃ²ng nháº­p tÃªn collection!")
            return

        with st.spinner("Äang crawl dá»¯ liá»‡u..."):
            try:
                loader = RecursiveUrlLoader(url,
                                            max_depth=2,
                                            extractor=bs4_extractor
                                            )
                documents = loader.load()

                filtered_documents = [
                    doc for doc in documents if len(doc.metadata.keys()) > 2]
                print("Check documents: ", len(filtered_documents))
                text_splitter = RecursiveCharacterTextSplitter(
                    chunk_size=4096, chunk_overlap=200)
                all_splits = text_splitter.split_documents(filtered_documents)

                all_chunks = []
                for i, chunk in enumerate(all_splits, start=1):
                    # print("Chunk metadata: ", chunk.metadata.keys())
                    chunk_metadata = {
                        "source": chunk.metadata["source"], "original_text": ""}
                    chunk_metadata.update({
                        "chunk_number": i,
                        "doc_id": generate_doc_id(chunk, chunk_metadata["source"], i),
                        "filename": chunk.metadata["title"]
                    })

                    output_data = {
                        "page_content": chunk.page_content,
                        "metadata": chunk_metadata
                    }
                    all_chunks.append(output_data)
                print("Check chunked documents: ", len(all_splits))
                seed_milvus('http://localhost:19530', all_chunks,
                            collection_name, use_ollama_embeddings)

                st.success(
                    f"ÄÃ£ crawl dá»¯ liá»‡u thÃ nh cÃ´ng vÃ o collection '{collection_name}'!")
            except Exception as e:
                print(f"Lá»—i khi crawl dá»¯ liá»‡u: {str(e)}")
                st.error(f"Lá»—i khi crawl dá»¯ liá»‡u: {str(e)}")


def handle_pdf_upload():
    files = st.file_uploader("Táº£i lÃªn PDF", type="pdf",
                             accept_multiple_files=True)
    print("Uploaded_file: ", files)
    for uploaded_file in files:
        with st.spinner("Äang xá»­ lÃ½ file PDF..."):
            try:
                handle_upload_file(uploaded_file)
                st.toast(
                    f"ÄÃ£ táº£i vÃ  xá»­ lÃ½ file {uploaded_file.name} thÃ nh cÃ´ng!", icon="âœ…")
            except Exception as e:
                st.toast(f"Lá»—i khi xá»­ lÃ½ file PDF: {str(e)}")

    return None


def setup_chat_interface(model_choice="OpenAI GPT-4o"):
    st.title("ğŸ’¬ CTU Chatbot Assistant")
    if model_choice == "OpenAI GPT-4o":
        st.caption("ğŸš€ Trá»£ lÃ½ AI Ä‘Æ°á»£c há»— trá»£ bá»Ÿi LangChain vÃ  OpenAI GPT-4o")
    else:
        st.caption("ğŸš€ Trá»£ lÃ½ AI Ä‘Æ°á»£c há»— trá»£ bá»Ÿi LangChain vÃ  Ollama LLaMA2")
    msgs = StreamlitChatMessageHistory(key="langchain_messages")

    if "messages" not in st.session_state:
        st.session_state.messages = [
            {"role": "assistant",
                "content": "ChÃ o má»«ng báº¡n Ä‘áº¿n vá»›i CTU Chabot Assistant! TÃ´i cÃ³ thá»ƒ há»— trá»£ gÃ¬ cho báº¡n?"}
        ]
        # msgs.add_ai_message(
        #     "ChÃ o má»«ng báº¡n Ä‘áº¿n vá»›i CTU Chabot Assistant! TÃ´i cÃ³ thá»ƒ há»— trá»£ gÃ¬ cho báº¡n?")

    # for msg in st.session_state.messages:
    #     role = "assistant" if msg["role"] == "assistant" else "human"
    #     st.chat_message(role).write(msg["content"])

    return msgs


def handle_user_input():
    for msg in st.session_state.messages:
        role = "assistant" if msg["role"] == "assistant" else "human"
        st.chat_message(role).write(msg["content"])
    col1, col2 = st.columns([3, 1])
    with col1:
        prompt = st.chat_input("HÃ£y há»i tÃ´i báº¥t cá»© Ä‘iá»u gÃ¬!")
    with col2:
        audio_bytes = audio_recorder(text="", icon_size="2x")

    if audio_bytes:
        with st.spinner("Transcribing..."):
            webm_file_path = "temp_audio.mp3"
            with open(webm_file_path, "wb") as f:
                f.write(audio_bytes)

            prompt = speech_to_text(webm_file_path)
            os.remove(webm_file_path)

    if prompt:
        st.session_state.messages.append({"role": "human", "content": prompt})
        st.chat_message("human").write(prompt)

        results = search_milvus(prompt)
        print("PROMT: ", prompt)

        formatted_results = []
        for doc in results:
            formatted_results.append({
                "content": doc.page_content,
                "source": doc.metadata.get("source", "Unknown"),
                "chunk_number": doc.metadata.get("chunk_number", "Unknown")
            })

        response = "Káº¿t quáº£ tÃ¬m kiáº¿m:\n\n"
        for idx, result in enumerate(formatted_results, 1):
            response += f"{idx}. Nguá»“n: {result['source']}\n"
            response += f"   Äoáº¡n sá»‘: {result['chunk_number']}\n"
            response += f"   Ná»™i dung: {result['content'][:200]}...\n\n"

        st.session_state.messages.append(
            {"role": "assistant", "content": response})

        # Use st.expander to hide/show search results
        with st.expander("Nháº¥n Ä‘á»ƒ xem káº¿t quáº£ tÃ¬m kiáº¿m"):
            st.write(response)

        ai_response = generate_answer(prompt, results)
        st.session_state.messages.append(
            {"role": "assistant", "content": ai_response})
        st.chat_message("assistant").write_stream(ai_response)


def main():
    initialize_app()
    data_source = setup_sidebar()
    setup_chat_interface()
    handle_user_input()


if __name__ == "__main__":
    main()
